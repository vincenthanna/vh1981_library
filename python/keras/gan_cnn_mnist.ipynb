{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import os\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "커스텀 loss function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_4d(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=(1,2,3)) # axis=()은 안에 있는 차원순서대로 하라는 뜻\n",
    "\n",
    "def mse_4d_tf(label, pred):\n",
    "    return tf.reduce_mean(tf.square(pred-label), axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54126451/what-does-axis-1-2-3-mean-in-k-sum-in-keras-backend\n",
    "pred = np.arange(start=0, stop=150).reshape((2, 3, 5, 5))\n",
    "label = np.arange(start=150, stop=300).reshape((2, 3, 5, 5))\n",
    "\n",
    "# import tensorflow as tf\n",
    "# with tf.Session() as session:\n",
    "#     a = mse_4d(pred, label)\n",
    "#     print(a.shape)\n",
    "#     print(a.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(models.Sequential):\n",
    "    def __init__(self, input_dim=64):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim        \n",
    "        self.generator = self.GENERATOR()\n",
    "        self.discriminator = self.DISCRIMINATOR()\n",
    "        self.add(self.generator)\n",
    "        self.discriminator.trainable = False\n",
    "        self.add(self.discriminator)\n",
    "        \n",
    "        self.compile_all()\n",
    "        \n",
    "    def compile_all(self):\n",
    "        d_optim = optimizers.SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        g_optim = optimizers.SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "        self.generator.compile(loss=mse_4d_tf, optimizer='SGD')\n",
    "        self.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)        \n",
    "        \n",
    "    def GENERATOR(self):\n",
    "        input_dim = self.input_dim\n",
    "        print(\"input_dim : \", input_dim)\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(1024, activation='tanh', input_dim=input_dim))\n",
    "        model.add(layers.Dense(128 * 7 * 7, activation='tanh'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Reshape((128, 7, 7), input_shape=(128 * 7 * 7,))) #이제 그림 모양으로 변경한다. 앞에가 채널번호임.\n",
    "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh'))\n",
    "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "        model.add(layers.Conv2D(1, (5, 5), padding='same', activation='tanh'))\n",
    "        return model\n",
    "        \n",
    "    def DISCRIMINATOR(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh', input_shape=(1, 28, 28)))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Conv2D(128, (5, 5), activation='tanh'))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(1024, activation='tanh'))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def get_random_image(self, data_count): #data_count는 batch_size라고 해도 좋을 듯하다.\n",
    "        input_dim = self.input_dim\n",
    "        return np.random.uniform(-1, 1, (data_count, input_dim))\n",
    "    \n",
    "    def train_both(self, x):\n",
    "        print(\"############ 1\")\n",
    "        ln = x.shape[0]\n",
    "        print(\"############ 2\")\n",
    "        # train discriminator\n",
    "        input_image = self.get_random_image(ln)\n",
    "        print(\"input_image.shape=\", input_image.shape)\n",
    "        w = self.generator.predict(input_image, verbose=0)\n",
    "        print(\"w.shape=\", w.shape)\n",
    "        xw = np.concatenate((x, w)) # 진짜 뒤에 가짜를 붙인다.\n",
    "        label = [1] * ln + [0] * ln # 진짜와 가짜를 붙였으므로 앞에것은 진짜 label(1), 뒤에것은 가짜 label(0)\n",
    "        #print(\"label.shape=\", np.array(label).shape)\n",
    "        label = np.array(label).reshape(-1, 1)\n",
    "        d_loss = self.discriminator.train_on_batch(xw, label)\n",
    "        print(\"############ 3\")\n",
    "        # train generator\n",
    "        input_image = self.get_random_image(ln)\n",
    "        self.discriminator.trainable = False #컴파일되어있는것도 참조해서 그런건가?\n",
    "        label = np.array([1] * ln).reshape(-1, 1)\n",
    "        print(\"label.shape=\", label.shape)\n",
    "        g_loss = self.train_on_batch(input_image, label)\n",
    "        self.discriminator.trainable = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(X_train, index, BATCH_SIZE):\n",
    "    return X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
    "\n",
    "def load_data(n_train):\n",
    "    (X_train, y_train), (_, _) = mnist.load_data()\n",
    "    return X_train[:n_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE, epochs, output_fold, input_dim, n_train):\n",
    "#     BATCH_SIZE = args.batch_size\n",
    "#     epochs = args.epochs\n",
    "#     output_fold = args.output_fold\n",
    "#     input_dim = args.input_dim\n",
    "#     n_train = args.n_train\n",
    "\n",
    "    X_train = load_data(n_train)\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "\n",
    "    gan = GAN(input_dim)\n",
    "    \n",
    "    d_loss_ll = []\n",
    "    g_loss_ll = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0] / BATCH_SIZE))\n",
    "\n",
    "        d_loss_l = []\n",
    "        g_loss_l = []\n",
    "        \n",
    "        for index in range(int(X_train.shape[0] / BATCH_SIZE)):\n",
    "            x = get_x(X_train, index, BATCH_SIZE)\n",
    "            \n",
    "            print(\"x.shape=\", x.shape)\n",
    "            (d_loss, g_loss) = gan.train_both(x)\n",
    "\n",
    "            d_loss_l.append(d_loss)\n",
    "            g_loss_l.append(g_loss)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            z = gan.get_z(x.shape[0])\n",
    "            w = gan.generator.predict(z, verbose=0)\n",
    "            #save_images(w, output_fold, epoch, 0)\n",
    "\n",
    "        d_loss_ll.append(d_loss_l)\n",
    "        g_loss_ll.append(g_loss_l)\n",
    "\n",
    "    gan.generator.save_weights(output_fold + '/' + 'generator', True)\n",
    "    gan.discriminator.save_weights(output_fold + '/' + 'discriminator', True)\n",
    "\n",
    "    np.savetxt(output_fold + '/' + 'd_loss', d_loss_ll)\n",
    "    np.savetxt(output_fold + '/' + 'g_loss', g_loss_ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim :  10\n",
      "Epoch is 0\n",
      "Number of batches 2\n",
      "x.shape= (16, 1, 28, 28)\n",
      "############ 1\n",
      "############ 2\n",
      "input_image.shape= (16, 10)\n",
      "w.shape= (16, 1, 28, 28)\n",
      "############ 3\n",
      "label.shape= (16, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GAN' object has no attribute '_output_tensor_cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-e3436822109b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-e3436822109b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#def train(BATCH_SIZE, epochs, output_fold, input_dim, n_train):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GAN_OUT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-369bdda9b07f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(BATCH_SIZE, epochs, output_fold, input_dim, n_train)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x.shape=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_both\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0md_loss_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-e5b4d4727f19>\u001b[0m in \u001b[0;36mtrain_both\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mln\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label.shape=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;31m# to match the value shapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_list_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mobject_list_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcache_key\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GAN' object has no attribute '_output_tensor_cache'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #def train(BATCH_SIZE, epochs, output_fold, input_dim, n_train):\n",
    "    train(16, 1000, 'GAN_OUT', 10, 32)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
